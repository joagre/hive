# Hive Actor Runtime - Consolidated Improvement Notes

This document consolidates all feedback and suggestions discussed so far.
It is intended as a working checklist to harden **Hive** as a real,
defensible actor runtime for embedded and safety-critical systems, and to
tighten its documentation so that its guarantees are precise and honest.

Nothing below changes Hive's philosophy. All suggestions preserve:
- single-threaded execution
- cooperative scheduling
- bounded memory
- no GC
- explicit failure handling

---

## 1. Core Runtime Improvements (Code)

### 1.1 Mailboxes and Selective Receive

**Problem**
- `recv_match` semantics are defined, but algorithmic cost is not.
- Current documentation implies O(1) hot paths, but selective receive can
  degenerate into unbounded scans.

**Required Fix**
Choose one and enforce it:

**Option A: Bounded scan**
- Define `MAX_MAILBOX_LEN` per actor (compile-time).
- Enforce hard rejection of sends when mailbox is full.
- Document that `recv_match` is O(MAX_MAILBOX_LEN), where MAX_MAILBOX_LEN is fixed.

**Option B: Indexed mailbox**
- Maintain per-actor buckets indexed by `(class, tag)` or similar.
- Matching cost becomes O(1) or amortized constant.

**Documentation Change**
- Explicitly state mailbox bounds.
- State the worst-case cost of `recv_match`.
- Clarify that "O(1) hot paths" refers to allocation and enqueue/dequeue,
  not semantic matching beyond the configured bound.

---

### 1.2 Guaranteed EXIT / Monitor Delivery

**Problem**
- EXIT and monitor notifications currently compete for the same pools as
  normal IPC.
- Under pool exhaustion, supervisors may miss actor death notifications.
- This breaks the "let it crash" model under stress.

**Required Fix**
Implement one of the following:

- Reserve a tiny, dedicated pool for EXIT and monitor messages.
- Or use a non-allocating side channel (per-actor exit list / flag).
- Or inline EXIT notifications in actor metadata, not mailbox entries.

**Guarantee to Document**
> EXIT and monitor notifications are guaranteed to be delivered unless the
> actor table itself is corrupt.

---

### 1.3 I/O Dispatch Starvation

**Problem**
- `epoll_wait()` is only called when the run queue is empty.
- If at least one actor is always runnable, I/O readiness can be deferred indefinitely.
- This can starve telemetry, timers, and TCP events.

**Required Fix**
Add bounded I/O polling:
- After N actor dispatches, perform `epoll_wait(timeout=0)` and drain a bounded
  number of events.
- N must be fixed and documented.

**Guarantee to Document**
- Worst-case I/O dispatch latency <= N actor dispatches.

---

### 1.4 Priority Starvation Guardrail (Optional but Strongly Recommended)

**Problem**
- Starvation across priority levels is acknowledged but unchecked.
- A single misbehaving CRITICAL actor can permanently suppress recovery,
  logging, and supervision.

**Recommended Fix (Compile-Time Option)**
Provide one optional mechanism:
- Per-actor instruction/time budget -> forced yield.
- Per-priority quota -> must schedule lower priority after N runs.
- Priority aging for waiting actors.

**Documentation**
- Make this opt-in.
- Clearly distinguish "strict deterministic priority" vs "bounded fairness".

---

### 1.5 File I/O Semantics

**Problem**
- File I/O stalls the entire scheduler.
- This is correct but dangerous if misunderstood.

**Recommended Improvements**
- Explicitly restrict file I/O to:
  - init / shutdown
  - low-priority actors
  - small, bounded operations
- Optionally provide chunked cooperative APIs.
- For MCUs, position file access as a "storage actor" pattern, not raw syscalls.

**Documentation**
- File I/O breaks real-time guarantees.
- File I/O is not safe for CRITICAL/HIGH actors.
- This is a deliberate trade-off, not an oversight.

---

## 2. Pilot Example Improvements (Code)

### 2.1 Motor Deadman Watchdog (Should Be Implemented)

**Problem**
- If upstream control actors crash, motors may retain last command.
- This is the most dangerous failure mode in an actor-based controller.

**Required Change**
Implement a motor deadman:
- If no valid torque command within N ticks (e.g. 3 ticks = 12 ms), zero motors.
- Use timer + timeout semantics.

**Rationale**
- Minimal code.
- Demonstrates correct use of timeouts.
- Makes the demo defensible and realistic.

---

### 2.2 Bus Retention on Subscribe (or Explicit Constraint)

**Problem**
- Late subscribers see no data until the next publish.
- Restarts depend on spawn ordering rituals.

**Recommended Fix**
- Support optional "retain latest on subscribe" when `max_entries=1`.

**If Not Implemented**
- Explicitly document the invariant:
  - Publishers must publish after all subscribers are up.
  - After restart, downstream actors see data only after the next publish.

---

### 2.3 Supervision Semantics Clarification

**Documentation Additions**
- Define the restart boundary:
  - On ONE_FOR_ALL restart, all integrators, filters, and state are reset.
- Explicitly mark comms as outside the flight-critical restart domain.

---

### 2.4 Error Handling Rules (Clarification)

Add these explicit rules:

- Returning from an actor entry function is equivalent to `hive_exit(CRASH)`.
- `HIVE_ERR_TIMEOUT` is not a crash condition by default.
- Pool exhaustion (`HIVE_ERR_NOMEM`) is a systemic error and should be surfaced.

This avoids accidental crashes on normal timeout paths.

---

### 2.5 Priority and Blocking Table (Documentation)

For the pilot example, document:
- Actor priorities.
- Primary blocking points per actor.
- Expected yield behavior.

This allows readers to audit latency and scheduling correctness.

---

## 3. Documentation Improvements (Runtime)

### 3.1 Guarantees vs Non-Guarantees Page

Add a blunt, testable list:

**Guaranteed**
- Bounded memory usage (calculable at link time).
- No heap allocation in hot paths.
- Single-threaded execution.
- Explicit yield points.
- EXIT/monitor delivery (after fix).
- Bounded I/O dispatch latency (after fix).

**Not Guaranteed**
- Starvation freedom across priorities (unless fairness enabled).
- Reproducible execution order when multiple I/O events fire simultaneously.
- Hard real-time deadlines across actors.

---

### 3.2 Failure Modes and Backpressure Patterns

Document:
- Pool exhaustion behavior.
- Recommended retry/backoff patterns.
- When to drop, retry, or escalate.
- How to detect systemic overload.

---

### 3.3 Memory Sizing Guide

Provide:
- Formulae for RAM usage based on config.
- Example configs:
  - 10 actors
  - 20 actors
  - Flight controller profile
- Explain stack arena sizing trade-offs.

---

### 3.4 Simulation Invariant

Document this explicitly:

> `hive_run_until_blocked()` must leave the system in a quiescent state.
> Any actor that fails to block or yield will cause unbounded simulation steps.

This makes simulation a correctness test, not just a demo.

---

## 4. Positioning Summary (For Docs / README)

Hive is:

- A **single-threaded, cooperative actor runtime**
- With **Erlang-inspired semantics**
- Designed for **MCUs and safety-conscious systems**
- Emphasizing **bounded memory, explicit failure, and predictable policy**

Hive is not:
- An RTOS
- A preemptive scheduler
- A hard real-time guarantee engine
- A statechart framework

**Honest tagline**
> "Erlang-style actors with deterministic memory and cooperative scheduling for embedded systems."

---

## 5. Bottom Line

With:
- bounded mailbox semantics,
- guaranteed EXIT delivery,
- bounded I/O dispatch latency,
- and a motor deadman in the pilot,

Hive crosses the line from "interesting" to "credible".

At that point, it is no longer a toy runtime or a thought experiment,
but a small, coherent concurrency substrate with a real example that
forces the design to stay honest.
